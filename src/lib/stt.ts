import { groq } from './gemini';
import { toFile } from 'groq-sdk';

export class SpeechToTextManager {
    private onFinal: (text: string) => void;

    constructor(onFinal: (text: string) => void) {
        this.onFinal = onFinal;
    }

    async recognizeBuffer(buffer: Buffer): Promise<string> {
        try {
            console.log('--- [STT] ðŸ“¡ Envoi reconnaissance buffer Ã  Groq Whisper...');

            // On construit manuellement l'objet File pour Ã©viter les soucis de compatibilitÃ© fs/path sur Vercel Edge/Node
            const transcription = await groq.audio.transcriptions.create({
                file: await (async () => {
                    const blob = new Blob([new Uint8Array(buffer)], { type: 'audio/webm' });
                    return new File([blob], "input.webm", { type: "audio/webm" });
                })(),
                model: "whisper-large-v3-turbo",
                language: "fr",
                response_format: "json",
            });

            let text = transcription.text || "";

            // Nettoyage des hallucinations frÃ©quentes de Whisper
            const hallucinations = [
                "Sous-titres rÃ©alisÃ©s par",
                "Sous-titres par",
                "Amara.org",
                "MBC",
                "L'Ã©quipe de",
                "pour les malentendants"
            ];

            if (hallucinations.some(h => text.includes(h)) || text.length < 2) {
                console.log('--- [STT] ðŸ—‘ï¸ Hallucination ou silence ignorÃ©:', text);
                return "";
            }

            if (text) {
                console.log('--- [STT] âœ… Transcription reÃ§ue (Whisper):', text);
            }
            return text;
        } catch (error) {
            console.error('--- [STT] âŒ Erreur recognizeBuffer (Whisper):', error);
            return "";
        }
    }

    stop() { }
}
